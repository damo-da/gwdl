{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc84049e-5188-4ada-bcff-6a12a6ff43af",
   "metadata": {},
   "source": [
    "# Preparing Noise dataset\n",
    "\n",
    "In this article, we will generate baseline (\"noise\") epochs and concatenate them\n",
    "with event epochs we generated previously and generate `X` and `y`, which will\n",
    "be the datasets for our machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e7e1e627-487f-464d-87a0-41e6bf37ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gwpy.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e3a5cfdb-209b-4981-8668-d3fd8e4b4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "import utils\n",
    "\n",
    "import conf\n",
    "\n",
    "importlib.reload(conf)\n",
    "importlib.reload(utils)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e347441-975f-40fe-a5c4-fc1217c6b70e",
   "metadata": {},
   "source": [
    "# Extracting epochs from event strains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30315fc6-69b2-4374-b52a-c5fa7ba50711",
   "metadata": {},
   "source": [
    "We utilize the same strain files for catalouged events and extract epochs\n",
    "non-overlapping with `[event_timestamp - dT, event_timestamp + dT]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e3c28d3e-170d-4145-81fd-983bca0159e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(conf.DATA_DIR / \"catalog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b2446d39-bf1f-44d7-a76f-45d1a96bc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_epochs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8e482b6b-c263-41e8-b1ff-54a9e8e06569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing noise 0/88\n",
      "Processing noise 1/88\n",
      "Processing noise 2/88\n",
      "Detected NaNs. Recreating...\n",
      "Processing noise 3/88\n",
      "Processing noise 4/88\n",
      "Processing noise 5/88\n",
      "Processing noise 6/88\n",
      "Processing noise 7/88\n",
      "Processing noise 8/88\n",
      "Processing noise 9/88\n",
      "Processing noise 10/88\n",
      "Processing noise 11/88\n",
      "Processing noise 12/88\n",
      "Processing noise 13/88\n",
      "Processing noise 14/88\n",
      "Detected NaNs. Recreating...\n",
      "Processing noise 15/88\n",
      "Processing noise 16/88\n",
      "Processing noise 17/88\n",
      "Detected NaNs. Recreating...\n",
      "Processing noise 18/88\n",
      "Processing noise 19/88\n",
      "Processing noise 20/88\n",
      "Processing noise 21/88\n",
      "Processing noise 22/88\n",
      "Processing noise 23/88\n",
      "Processing noise 24/88\n",
      "Detected NaNs. Recreating...\n",
      "Processing noise 25/88\n",
      "Processing noise 26/88\n",
      "Processing noise 27/88\n",
      "Processing noise 28/88\n",
      "Processing noise 29/88\n",
      "Processing noise 30/88\n",
      "Processing noise 31/88\n",
      "Processing noise 32/88\n",
      "Processing noise 33/88\n",
      "Processing noise 34/88\n",
      "Processing noise 35/88\n",
      "Detected NaNs. Recreating...\n",
      "Processing noise 36/88\n",
      "Processing noise 37/88\n",
      "Detected NaNs. Recreating...\n",
      "Detected NaNs. Recreating...\n",
      "Processing noise 38/88\n",
      "Processing noise 39/88\n",
      "Processing noise 40/88\n",
      "Processing noise 41/88\n",
      "Processing noise 42/88\n",
      "Processing noise 43/88\n",
      "Processing noise 44/88\n",
      "Processing noise 45/88\n",
      "Processing noise 46/88\n",
      "Processing noise 47/88\n",
      "Processing noise 48/88\n",
      "Processing noise 49/88\n",
      "Processing noise 50/88\n",
      "Processing noise 51/88\n",
      "Processing noise 52/88\n",
      "Processing noise 53/88\n",
      "Processing noise 54/88\n",
      "Processing noise 55/88\n",
      "Processing noise 56/88\n",
      "Processing noise 57/88\n",
      "Processing noise 58/88\n",
      "Processing noise 59/88\n",
      "Processing noise 60/88\n",
      "Processing noise 61/88\n",
      "Processing noise 62/88\n",
      "Processing noise 63/88\n",
      "Processing noise 64/88\n",
      "Processing noise 65/88\n",
      "Processing noise 66/88\n",
      "Processing noise 67/88\n",
      "Processing noise 68/88\n",
      "Processing noise 69/88\n",
      "Processing noise 70/88\n",
      "Processing noise 71/88\n",
      "Processing noise 72/88\n",
      "Processing noise 73/88\n",
      "Processing noise 74/88\n",
      "Processing noise 75/88\n",
      "Processing noise 76/88\n",
      "Processing noise 77/88\n",
      "Processing noise 78/88\n",
      "Processing noise 79/88\n",
      "Processing noise 80/88\n",
      "Processing noise 81/88\n",
      "Processing noise 82/88\n",
      "Processing noise 83/88\n",
      "Processing noise 84/88\n",
      "Processing noise 85/88\n",
      "Processing noise 86/88\n",
      "Processing noise 87/88\n"
     ]
    }
   ],
   "source": [
    "for i, row in catalog.iterrows():\n",
    "  print(f\"Processing noise {i}/{len(catalog)}\")\n",
    "  \n",
    "  h1f, l1f = Path(row[\"h1_strain\"]), Path(row[\"l1_strain\"])\n",
    "  \n",
    "  h1s = TimeSeries.read(h1f, format='hdf5.losc')\n",
    "  l1s = TimeSeries.read(l1f, format='hdf5.losc')\n",
    "  \n",
    "  t0 = utils.get_file_timestamp(h1f)\n",
    "  \n",
    "  event_ts = row[\"timestamp\"]\n",
    "  \n",
    "  while True:\n",
    "    t = t0 + np.random.randint(conf.dT, 4096 - conf.dT)\n",
    "    start, end = t - conf.dT, t + conf.dT  \n",
    "\n",
    "    h1_ts = h1s.crop(start, end, copy=True)\n",
    "    l1_ts = l1s.crop(start, end, copy=True)\n",
    "    \n",
    "    if not ((end < t0 - conf.dT) or (start > t0 + conf.dT)):\n",
    "      print(\"Baseline overlaps with event. Recreating...\")\n",
    "    if (np.isnan(h1_ts).any() or np.isnan(l1_ts).any()):\n",
    "      print(\"Detected NaNs. Recreating...\")\n",
    "    else:\n",
    "      break\n",
    "\n",
    "  del h1s, l1s\n",
    "\n",
    "  noise_epochs.append([h1_ts, l1_ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "01a0217a-1d7d-4788-8dd4-dd02dfdcf157",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (conf.DATA_DIR / \"noises.npy\").open(\"wb\") as f:\n",
    "  pickle.dump(noise_epochs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbede179-510c-466c-be9d-46415f94f6ce",
   "metadata": {},
   "source": [
    "# Merging event and noise datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0d3d274a-a1c9-4048-92cb-fd8f550b024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (conf.DATA_DIR / \"events.npy\").open(\"rb\") as f:\n",
    "  event_epochs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a43ccbf8-9c34-4dce-b98a-becba470f3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 88, 176)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = epochs = event_epochs + noise_epochs\n",
    "\n",
    "len(event_epochs), len(noise_epochs), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0eec6ca1-c7a3-445c-9342-42656fe4612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (conf.DATA_DIR / \"X.npy\").open(\"wb\") as f:\n",
    "  pickle.dump(X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b0d94b5f-5ee0-4516-bbe3-a6f624414a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([1] * len(event_epochs) + [0] * len(noise_epochs))\n",
    "\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "040a67d4-7ff4-4b80-b893-6c642f248e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (conf.DATA_DIR / \"y.npy\").open(\"wb\") as f:\n",
    "  pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20c234-60b8-46df-8f54-9033c67506c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
